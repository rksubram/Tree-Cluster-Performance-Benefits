{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/all_data.csv').T\n",
    "labels = pd.read_csv('data/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.drop('type_sample', axis=1, inplace=True)\n",
    "labels = labels.reset_index(drop=True)\n",
    "labels.rename(columns={ labels.columns[0]: \"Participant\" }, inplace=True)\n",
    "labels.IBD = labels.IBD.astype('bool')\n",
    "\n",
    "data = data.reset_index()\n",
    "data.columns = data.iloc[0]\n",
    "data = data.iloc[1:]\n",
    "data = data.reset_index(drop=True)\n",
    "data.rename(columns={ data.columns[0]: \"Participant\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Val Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, seed = 43, train_val_test_split = (80,10,10)):\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_val_test_split[0]*len(indices)//100]\n",
    "    val_indices = indices[train_val_test_split[0]*len(indices)//100:train_val_test_split[0]*len(indices)//100\\\n",
    "                          + train_val_test_split[1]*len(indices)//100]\n",
    "    test_indices = indices[train_val_test_split[0]*len(indices)//100+ train_val_test_split[1]*len(indices)//100:]\n",
    "    \n",
    "    return data.iloc[train_indices], data.iloc[val_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(data)\n",
    "train_labels, val_labels, test_labels = split_data(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_data.iloc[:, 1:])\n",
    "\n",
    "scaled_train_data = scaler.transform(train_data.iloc[:, 1:])\n",
    "scaled_test_data = scaler.transform(test_data.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "pca = PCA(10)\n",
    "svd = TruncatedSVD(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_data = pca.fit_transform(train_data.iloc[:, 1:])\n",
    "svd_train_data = svd.fit_transform(train_data.iloc[:, 1:])\n",
    "\n",
    "pca_test_data = pca.transform(test_data.iloc[:, 1:])\n",
    "svd_test_data = svd.transform(test_data.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=43, criterion='entropy')\n",
    "rfc.fit(train_data.iloc[:, 1:], train_labels['IBD'])\n",
    "\n",
    "test_pred = rfc.predict(test_data.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score = 0.6491525423728814\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.67      0.40      0.50        30\n",
      "       True       0.75      0.90      0.82        59\n",
      "\n",
      "avg / total       0.72      0.73      0.71        89\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12 18]\n",
      " [ 6 53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(\"ROC score = {}\".format(roc_auc_score(test_labels['IBD'], test_pred)))\n",
    "print(\"\\nClassification Report:\") \n",
    "print(classification_report(test_labels['IBD'], test_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_labels['IBD'], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score = 0.5994350282485876\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.67      0.27      0.38        30\n",
      "       True       0.71      0.93      0.81        59\n",
      "\n",
      "avg / total       0.70      0.71      0.66        89\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8 22]\n",
      " [ 4 55]]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(pca_train_data, train_labels['IBD'])\n",
    "pca_test_pred = rfc.predict(pca_test_data)\n",
    "\n",
    "print(\"ROC score = {}\".format(roc_auc_score(test_labels['IBD'], pca_test_pred)))\n",
    "print(\"\\nClassification Report:\") \n",
    "print(classification_report(test_labels['IBD'], pca_test_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_labels['IBD'], pca_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score = 0.7242937853107344\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.53      0.63        30\n",
      "       True       0.79      0.92      0.85        59\n",
      "\n",
      "avg / total       0.78      0.79      0.78        89\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16 14]\n",
      " [ 5 54]]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(svd_train_data, train_labels['IBD'])\n",
    "svd_test_pred = rfc.predict(svd_test_data)\n",
    "\n",
    "print(\"ROC score = {}\".format(roc_auc_score(test_labels['IBD'], svd_test_pred)))\n",
    "print(\"\\nClassification Report:\") \n",
    "print(classification_report(test_labels['IBD'], svd_test_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_labels['IBD'], svd_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
